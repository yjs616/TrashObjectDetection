# Copyright (c) OpenMMLab. All rights reserved.
#ë™ì˜ìƒì— ìˆëŠ” ê°ì²´ ì‹¤ì‹œê°„ìœ¼ë¡œ íƒì§€í•˜ëŠ” ì½”ë“œ 

import streamlit as st
import cv2
import torch
import json
from mmdet.apis import inference_detector, init_detector
from mmdet.registry import VISUALIZERS
from mmengine import Config
from PIL import Image
import numpy as np  # numpy ëª¨ë“ˆ ì¶”ê°€

#target_width = 640

# JSON íŒŒì¼ì—ì„œ í´ë˜ìŠ¤ ì •ë³´ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” í•¨ìˆ˜
def load_class_info(file_path="class_info.json"):
    with open(file_path, 'r', encoding='utf-8') as f:
        return json.load(f)

#"/data/ephemeral/home/class_info.json"
# JSON íŒŒì¼ì—ì„œ ì •ë³´ë¥¼ ë¶ˆëŸ¬ì˜¤ê¸°
class_info = load_class_info()

# CSS ìŠ¤íƒ€ì¼ì„ ì„¤ì •í•˜ëŠ” í•¨ìˆ˜
def apply_css():
    st.markdown("""
        <style>
        @import url('https://fonts.googleapis.com/css2?family=Gowun+Dodum&display=swap');
        
        .stApp {
            background-color: #d7f5d5;
        }
        * {
            font-family: 'Gowun Dodum', sans-serif;
            color: #333333;
        }
        .title-text {
            font-size: 36px;
            color: #333333;
            font-family: 'Gowun Dodum', sans-serif;
            margin-bottom: 30px;
        }
        .detected-object-text {
            font-size: 36px;
            color: #333333;
            font-family: 'Gowun Dodum', sans-serif;
            text-align: center;
            margin-bottom: 20px;
        }
        .stButton {
            display: flex;
            justify-content: center;
        }
        div.stButton > button:first-child {
            display: inline-block;
            width: 700px;
            margin: 0 auto;
            padding: 15px 0;
            background-color: #92BA83;
            border: none;
            border-radius: 20px;
            font-size: 24px;
            color: #333333;
            cursor: pointer;
            box-shadow: 3px 3px 10px rgba(0, 0, 0, 0.2);
            position: relative;
        }
        </style>
    """, unsafe_allow_html=True)

def display_class_info(detected_class, info_area):
    info = class_info.get(detected_class)
    if info:
        # ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ë¥¼ í•¨ê»˜ í‘œì‹œí•  HTML í…œí”Œë¦¿ì„ ìƒì„±
        content = f"""
        <div style="text-align: center;">
            <img src="{info['image_path']}" width="200" style="margin-bottom: 20px;">
            <h3 class='detected-object-text'>ë‚˜ì•¼, {info['name']}</h3>
            <p>{info['description']}</p>
        </div>
        """

        # info_areaì— í•œ ë²ˆì— ì½˜í…ì¸ ë¥¼ ì—…ë°ì´íŠ¸
        info_area.markdown(content, unsafe_allow_html=True)
    else:
        info_area.markdown("ì•Œ ìˆ˜ ì—†ëŠ” ê°ì²´ì…ë‹ˆë‹¤.")


# ì‹¤ì‹œê°„ ê°ì²´ ê°ì§€ í•¨ìˆ˜
def show_real_time_detection(config_path, checkpoint_path, video_path, show_info=True):
    apply_css()
    st.markdown("<h1 class='title-text'>ì§€êµ¬ ì§€í‚¤ëŠ” ì¤‘ ğŸŒ</h1>", unsafe_allow_html=True)

    # ëª¨ë¸ ì´ˆê¸°í™”
    device = 'cuda:0' if torch.cuda.is_available() else 'cpu'
    cfg = Config.fromfile(config_path)
    if 'roi_head' in cfg.model:
        cfg.model.roi_head.mask_head = None
        cfg.model.roi_head.bbox_head.num_classes = 10

    # í´ë˜ìŠ¤ ì •ë³´ ì„¤ì •
    metainfo = {
        'classes': ("General trash", "Paper", "Paper pack", "Metal", "Glass", "Plastic", 
                    "Styrofoam", "Plastic bag", "Battery", "Clothing")
    }

    model = init_detector(cfg, checkpoint_path, device=device)
    visualizer = VISUALIZERS.build(model.cfg.visualizer)
    visualizer.dataset_meta = metainfo

    # í´ë˜ìŠ¤ IDì™€ í•œêµ­ì–´ ì´ë¦„ ë§¤í•‘
    class_name_mapping = {
        "General trash": "ì¼ë°˜ì“°ë ˆê¸° ğŸ—‘ï¸",
        "Paper": "ì¢…ì´ ğŸ“ƒ",
        "Paper pack": "ì¢…ì´íŒ© ğŸ§ƒ",
        "Metal": "ê¸ˆì†ğŸ¥«",
        "Glass": "ìœ ë¦¬ğŸ¸",
        "Plastic": "í”Œë¼ìŠ¤í‹± ğŸ—‘ï¸",
        "Styrofoam": "ìŠ¤í‹°ë¡œí¼ ğŸ—‘ï¸",
        "Plastic bag": "ë¹„ë‹ë´‰ì§€ ğŸ—‘ï¸",
        "Battery": "ë°°í„°ë¦¬ ğŸ”‹",
        "Clothing": "ì˜ë¥˜ ğŸ‘•"
    }

    # ë¹„ë””ì˜¤ íŒŒì¼ ì—´ê¸°
    cap = cv2.VideoCapture(video_path)


    stframe = st.empty()  # Streamlit í”„ë ˆì„ ìƒì„±
    detected_text = st.empty()  # ê°ì²´ ì´ë¦„ì„ í‘œì‹œí•  í…ìŠ¤íŠ¸ ê³µê°„
    info_area = st.empty()  # ê°ì²´ ì •ë³´ë¥¼ í‘œì‹œí•  ê³ ì • ê³µê°„

    if st.button("ë’¤ë¡œê°€ê¸° ğŸ”™", key="back_button"):
        st.session_state.page = 'next'
        st.rerun()
        return

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            st.warning("ë¹„ë””ì˜¤ í”„ë ˆì„ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¹„ë””ì˜¤ ê²½ë¡œë‚˜ íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
            break

        # frameì´ numpy ë°°ì—´ì¸ì§€ í™•ì¸
        if not isinstance(frame, np.ndarray):
            st.error("í”„ë ˆì„ ë°ì´í„°ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            break

        result = inference_detector(model, frame)
        detected_objects = [obj for obj in result.pred_instances if obj.scores > 0.5]
        
        if len(detected_objects) == 1:
            class_id = int(detected_objects[0].labels)
            class_name = visualizer.dataset_meta['classes'][class_id]
            korean_name = class_name_mapping.get(class_name, "ì•Œ ìˆ˜ ì—†ëŠ” ê°ì²´")
            detected_text.markdown(f"<h2 class='detected-object-text'>{korean_name}</h2>", unsafe_allow_html=True)
            if show_info:
                display_class_info(class_name, info_area)  # ê°ì²´ ì •ë³´ ì—…ë°ì´íŠ¸

        elif len(detected_objects) > 1:
            detected_text.markdown("<h2 class='detected-object-text'>í•œ ê°œë§Œ ë³´ì—¬ì£¼ì„¸ìš”!</h2>", unsafe_allow_html=True)
            info_area.empty()  # ì¤‘ë³µ íƒì§€ ì‹œ ì •ë³´ ì°½ ë¹„ìš°ê¸°
        else:
            detected_text.markdown("<h2 class='detected-object-text'></h2>", unsafe_allow_html=True)
            info_area.empty()  # íƒì§€ëœ ê°ì²´ê°€ ì—†ìœ¼ë©´ ì •ë³´ ì°½ ë¹„ìš°ê¸°

        visualizer.add_datasample(
            name='result', image=frame, data_sample=result,
            draw_gt=False, pred_score_thr=0.5, show=False
        )

        display_img = visualizer.get_image()
        display_img = cv2.cvtColor(display_img, cv2.COLOR_BGR2RGB)
        
        stframe.image(display_img, channels="RGB", use_column_width=True) #True

    cap.release()

