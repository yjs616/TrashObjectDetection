# Copyright (c) OpenMMLab. All rights reserved.
#ì‹¤ì‹œê°„ ì›¹ìº ìœ¼ë¡œ ê°ì²´ íƒì§€í•˜ëŠ” ì½”ë“œ

import streamlit as st
import cv2
import torch
import json
from mmdet.apis import inference_detector, init_detector
from mmdet.registry import VISUALIZERS
from mmengine import Config
import numpy as np

# JSON íŒŒì¼ì—ì„œ í´ë˜ìŠ¤ ì •ë³´ë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ” í•¨ìˆ˜
def load_class_info(file_path="class_info.json"):
    with open(file_path, 'r', encoding='utf-8') as f:
        return json.load(f)

# JSON íŒŒì¼ì—ì„œ ì •ë³´ë¥¼ ë¶ˆëŸ¬ì˜¤ê¸°
class_info = load_class_info()

# CSS ìŠ¤íƒ€ì¼ì„ ì„¤ì •í•˜ëŠ” í•¨ìˆ˜
def apply_css():
    st.markdown("""
        <style>
        @import url('https://fonts.googleapis.com/css2?family=Gowun+Dodum&display=swap');

        .stApp {
            background-color: #d7f5d5;
        }
        * {
            font-family: 'Gowun Dodum', sans-serif;
            color: #333333;
        }
        .title-text {
            font-size: 36px;
            color: #333333;
            font-family: 'Gowun Dodum', sans-serif;
            margin-bottom: 30px;
        }
        .detected-object-text {
            font-size: 36px;
            color: #333333;
            font-family: 'Gowun Dodum', sans-serif;
            text-align: center;
            margin-bottom: 20px;
        }
        .stButton {
            display: flex;
            justify-content: center;
        }
        div.stButton > button:first-child {
            display: inline-block;
            width: 700px;
            margin: 0 auto;
            padding: 15px 0;
            background-color: #92BA83;
            border: none;
            border-radius: 20px;
            font-size: 24px;
            color: #333333;
            cursor: pointer;
            box-shadow: 3px 3px 10px rgba(0, 0, 0, 0.2);
            position: relative;
        }
        </style>
    """, unsafe_allow_html=True)

def display_class_info(detected_class, info_area):
    info = class_info.get(detected_class)
    if info:
        # ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ë¥¼ í•¨ê»˜ í‘œì‹œí•  HTML í…œí”Œë¦¿ì„ ìƒì„±
        content = f"""
        <div style="text-align: center;">
            <img src="{info['image_path']}" width="200" style="margin-bottom: 20px;">
            <h3 class='detected-object-text'>ë‚˜ì•¼, {info['name']}</h3>
            <p>{info['description']}</p>
        </div>
        """
        # info_areaì— í•œ ë²ˆì— ì½˜í…ì¸ ë¥¼ ì—…ë°ì´íŠ¸
        info_area.markdown(content, unsafe_allow_html=True)
    else:
        info_area.markdown("ì•Œ ìˆ˜ ì—†ëŠ” ê°ì²´ì…ë‹ˆë‹¤.")

def show_real_time_detection(config_path, checkpoint_path):
    apply_css()
    st.markdown("<h1 class='title-text'>ì§€êµ¬ ì§€í‚¤ëŠ” ì¤‘ ğŸŒ</h1>", unsafe_allow_html=True)

    # ëª¨ë¸ ì´ˆê¸°í™”
    device = 'cuda:0' if torch.cuda.is_available() else 'cpu'
    cfg = Config.fromfile(config_path)
    if 'roi_head' in cfg.model:
        cfg.model.roi_head.mask_head = None
        cfg.model.roi_head.bbox_head.num_classes = 10

    # í´ë˜ìŠ¤ ì •ë³´ ì„¤ì •
    metainfo = {
        'classes': ("General trash", "Paper", "Paper pack", "Metal", "Glass", "Plastic", 
                    "Styrofoam", "Plastic bag", "Battery", "Clothing")
    }

    model = init_detector(cfg, checkpoint_path, device=device)
    visualizer = VISUALIZERS.build(model.cfg.visualizer)
    visualizer.dataset_meta = metainfo

    # ì›¹ìº  ì„¤ì •
    cap = cv2.VideoCapture(0)

    if not cap.isOpened():
        st.error("ì›¹ìº ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    stframe = st.empty()  # Streamlit í”„ë ˆì„ ìƒì„±
    detected_text = st.empty()  # ê°ì²´ ì´ë¦„ì„ í‘œì‹œí•  í…ìŠ¤íŠ¸ ê³µê°„
    info_area = st.empty()  # ê°ì²´ ì •ë³´ë¥¼ í‘œì‹œí•  ê³ ì • ê³µê°„

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            st.warning("ì›¹ìº ì—ì„œ í”„ë ˆì„ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            break

        # frameì´ numpy ë°°ì—´ì¸ì§€ í™•ì¸
        if not isinstance(frame, np.ndarray):
            st.error("í”„ë ˆì„ ë°ì´í„°ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            break

        result = inference_detector(model, frame)
        detected_objects = [obj for obj in result.pred_instances if obj.scores > 0.5]

        if len(detected_objects) == 1:
            class_id = int(detected_objects[0].labels)
            class_name = visualizer.dataset_meta['classes'][class_id]
            detected_text.markdown(f"<h2 class='detected-object-text'>{class_name}</h2>", unsafe_allow_html=True)
            display_class_info(class_name, info_area)  # ê°ì²´ ì •ë³´ ì—…ë°ì´íŠ¸

        elif len(detected_objects) > 1:
            detected_text.markdown("<h2 class='detected-object-text'>í•œ ê°œë§Œ ë³´ì—¬ì£¼ì„¸ìš”!</h2>", unsafe_allow_html=True)
            info_area.empty()  # ì¤‘ë³µ íƒì§€ ì‹œ ì •ë³´ ì°½ ë¹„ìš°ê¸°
        else:
            detected_text.markdown("<h2 class='detected-object-text'></h2>", unsafe_allow_html=True)
            info_area.empty()  # íƒì§€ëœ ê°ì²´ê°€ ì—†ìœ¼ë©´ ì •ë³´ ì°½ ë¹„ìš°ê¸°

        visualizer.add_datasample(
            name='result', image=frame, data_sample=result,
            draw_gt=False, pred_score_thr=0.5, show=False
        )

        # ì‹œê°í™”ëœ ì´ë¯¸ì§€ë¥¼ ì–»ê³  RGBë¡œ ë³€í™˜
        display_img = visualizer.get_image()
        display_img = cv2.cvtColor(display_img, cv2.COLOR_BGR2RGB)

        # Streamlitì— ì´ë¯¸ì§€ í‘œì‹œ
        stframe.image(display_img, channels="RGB", use_column_width=True)

    cap.release()

if __name__ == '__main__':
    # ì„¤ì • íŒŒì¼ê³¼ ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ ê²½ë¡œ ì§€ì •
    config_path = '/data/ephemeral/home/TrashObjectDetection/mmdetection/configs/swin/faster_rcnn_swin-s-p4-w7_fpn_fp16_ms-crop-3x_coco.py'
    checkpoint_path = '/data/ephemeral/home/TrashObjectDetection/mmdetection/work_dirs/epoch_36.pth'

    show_real_time_detection(config_path, checkpoint_path)
